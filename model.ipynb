{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319448ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#importing visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#importing logging\n",
    "import logging\n",
    "logging.basicConfig(filename = 'model.log', level = logging.INFO,filemode='w', format = '%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "#importing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1e5c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://raw.githubusercontent.com/Frisk516/mobile_prices_MLModel/refs/heads/main/Cellphone.csv\"\n",
    "df=pd.read_csv(url,sep=',')\n",
    "df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a394a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plot boxplots and bell curves for each numerical feature\n",
    "for col in df:\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    \n",
    "    # Boxplot (shows outliers as points beyond whiskers)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "    \n",
    "    # Bell curve: histogram + KDE (to check distribution shape)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(df[col], kde=True, bins=30)\n",
    "    plt.title(f'Histogram & KDE of {col}')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8f7889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ebc1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing EDA\n",
    "\n",
    "from collections import OrderedDict\n",
    "stats=[]\n",
    "for i in df:\n",
    "    numerical_stats=OrderedDict({\n",
    "        'feature':i,\n",
    "        'mean':df[i].mean(),\n",
    "        'median':df[i].median(),\n",
    "        'mode':df[i].mode()[0],\n",
    "        'std':df[i].std(),\n",
    "        'min':df[i].min(),\n",
    "        'max':df[i].max(),\n",
    "        'skewness':df[i].skew(),\n",
    "        'kurtosis':df[i].kurt()\n",
    "    })\n",
    "    stats.append(numerical_stats)\n",
    "    report=pd.DataFrame(stats)\n",
    "\n",
    "\n",
    "# Outlier Identification :\n",
    "outlier_label = []\n",
    "for col in report['feature']:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    LW = Q1 - 1.5 * IQR   # LW : Lower Whisker Line\n",
    "    UW = Q3 + 1.5 * IQR   # UW : Upper Whisker Line\n",
    "    outliers = df[(df[col] < LW) | (df[col] > UW)]\n",
    "    if not outliers.empty:\n",
    "        outlier_label.append(\"Has Outliers\")\n",
    "    else:\n",
    "        outlier_label.append(\"No Outliers\")\n",
    "\n",
    "report[\"Outlier Comment\"] = outlier_label\n",
    "\n",
    "# Checking Report\n",
    "report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c62d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split to prevent data leak\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=df.drop('Price',axis=1)\n",
    "y=df['Price']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427160f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying minmax scaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c94fea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using linear regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LR=LinearRegression()\n",
    "\n",
    "LR.fit(X_train,y_train)\n",
    "\n",
    "y_pred_LR=LR.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
    "\n",
    "r2_score_LR=r2_score(y_test,y_pred_LR)\n",
    "r2_score_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a8642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "RF=RandomForestRegressor()\n",
    "\n",
    "RF.fit(X_train,y_train)\n",
    "\n",
    "y_pred_RF=RF.predict(X_test)\n",
    "\n",
    "r2_score_RF = r2_score(y_test,y_pred_RF)\n",
    "print(f'The R2 Score for ',r2_score_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379671cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "DT=DecisionTreeRegressor()\n",
    "\n",
    "DT.fit(X_train,y_train)\n",
    "\n",
    "y_pred_DT=DT.predict(X_test)\n",
    "\n",
    "r2_score_DT=r2_score(y_test,y_pred_DT)\n",
    "r2_score_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d187c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "XGB = xgb.XGBRegressor()\n",
    "\n",
    "XGB.fit(X_train, y_train)\n",
    "\n",
    "y_pred_XGB = XGB.predict(X_test)\n",
    "\n",
    "r2_score_XGB = r2_score(y_test, y_pred_XGB)\n",
    "\n",
    "print(f'The R2 Score for XGBoost Model: {r2_score_XGB}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26613c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ADA=AdaBoostRegressor()\n",
    "\n",
    "ADA.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ADA = ADA.predict(X_test)\n",
    "\n",
    "r2_score_ADA = r2_score(y_test, y_pred_ADA)\n",
    "\n",
    "print(f'The R2 Score for AdaBoost Model: {r2_score_ADA}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8274e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define model and parameter grid\n",
    "model=RandomForestRegressor(random_state=42)\n",
    "param_grid = {'n_estimators': [25,50,100, 200, 300, 400,500],'max_depth': [None, 10,20,30,40,50]}\n",
    "\n",
    "#Grid Search Cv\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred=best_model.predict(X_test)\n",
    "\n",
    "#print result\n",
    "print('Best Parameters:', grid_search.best_params_)\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39619c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest gave the best result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
